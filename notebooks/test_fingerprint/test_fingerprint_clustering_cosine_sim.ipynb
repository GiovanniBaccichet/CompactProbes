{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.autonotebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "string_df = pd.read_csv(\"../../data/interim/string_df.csv\", index_col=0)\n",
    "\n",
    "balanced_pairs_df = pd.read_csv(\"../../data/train_test/test_pairs.csv\", index_col=0)\n",
    "\n",
    "balanced_pairs_df.drop_duplicates(inplace=True)\n",
    "balanced_pairs_df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>concatenated</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>GooglePixel3A_L</th>\n",
       "      <td>0000000000000000000000000000000000000000000000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GooglePixel3A_L</th>\n",
       "      <td>0000000000000000000000000000000000000000000000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GooglePixel3A_L</th>\n",
       "      <td>0000000000000000000000000000000000000000000000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GooglePixel3A_L</th>\n",
       "      <td>0000000000000000000000000000000000000000000000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GooglePixel3A_L</th>\n",
       "      <td>0000000000000000000000000000000000000000000000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>iPhoneXSMax_M</th>\n",
       "      <td>0001101000101101000000000001101111111111000000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>iPhoneXSMax_M</th>\n",
       "      <td>0001101000101101010000000001101111111111000000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>iPhoneXSMax_M</th>\n",
       "      <td>0001101000101101000000000001101111111111000000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>iPhoneXSMax_M</th>\n",
       "      <td>0001101000101101010000000001101111111111000000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>iPhoneXSMax_M</th>\n",
       "      <td>0001101000101101010000000001101111111111000000...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>956 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      concatenated\n",
       "label                                                             \n",
       "GooglePixel3A_L  0000000000000000000000000000000000000000000000...\n",
       "GooglePixel3A_L  0000000000000000000000000000000000000000000000...\n",
       "GooglePixel3A_L  0000000000000000000000000000000000000000000000...\n",
       "GooglePixel3A_L  0000000000000000000000000000000000000000000000...\n",
       "GooglePixel3A_L  0000000000000000000000000000000000000000000000...\n",
       "...                                                            ...\n",
       "iPhoneXSMax_M    0001101000101101000000000001101111111111000000...\n",
       "iPhoneXSMax_M    0001101000101101010000000001101111111111000000...\n",
       "iPhoneXSMax_M    0001101000101101000000000001101111111111000000...\n",
       "iPhoneXSMax_M    0001101000101101010000000001101111111111000000...\n",
       "iPhoneXSMax_M    0001101000101101010000000001101111111111000000...\n",
       "\n",
       "[956 rows x 1 columns]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "string_df[\"concatenated\"] = string_df[\"concatenated\"].apply(\n",
    "    lambda x: np.array(list(x)).astype(int)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Best Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def parse_log_file(filename):\n",
    "    data = []\n",
    "\n",
    "    with open(filename, \"r\") as file:\n",
    "        lines = file.readlines()\n",
    "\n",
    "        current_filter = None\n",
    "        current_threshold = None\n",
    "        current_min_error = None\n",
    "        current_confidence = None\n",
    "\n",
    "        for line in lines:\n",
    "            if \"Best Filter\" in line:\n",
    "                # Extract Best Filter using regex\n",
    "                filter_match = re.search(r\"Best Filter: (.+)\", line)\n",
    "                if filter_match:\n",
    "                    current_filter = filter_match.group(1).strip()\n",
    "\n",
    "            elif \"Best Threshold\" in line:\n",
    "                # Extract Best Threshold using regex\n",
    "                threshold_match = re.search(r\"Best Threshold: (.+)\", line)\n",
    "                if threshold_match:\n",
    "                    current_threshold = int(threshold_match.group(1).strip())\n",
    "\n",
    "            elif \"Min error\" in line:\n",
    "                # Extract Min Error using regex\n",
    "                min_error_match = re.search(r\"Min error: (.+)\", line)\n",
    "                if min_error_match:\n",
    "                    current_min_error = float(min_error_match.group(1).strip())\n",
    "\n",
    "            elif \"Confidence\" in line:\n",
    "                # Extract Confidence using regex\n",
    "                confidence_match = re.search(r\"Confidence: (.+)\", line)\n",
    "                if confidence_match:\n",
    "                    current_confidence = float(confidence_match.group(1).strip())\n",
    "\n",
    "                    # Once we have all values, create a tuple and add it to the data list\n",
    "                    data.append(\n",
    "                        (\n",
    "                            current_filter,\n",
    "                            current_threshold,\n",
    "                            current_min_error,\n",
    "                            current_confidence,\n",
    "                        )\n",
    "                    )\n",
    "\n",
    "                    # Reset current values for the next entry\n",
    "                    current_filter = None\n",
    "                    current_threshold = None\n",
    "                    current_min_error = None\n",
    "                    current_confidence = None\n",
    "\n",
    "    # Convert the list of tuples into a DataFrame\n",
    "    df = pd.DataFrame(\n",
    "        data, columns=[\"Best Filter\", \"Best Threshold\", \"Min Error\", \"Confidence\"]\n",
    "    )\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usage example:\n",
    "filename = \"../../reports/best_config\"\n",
    "best_configs_df = parse_log_file(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Best Filter</th>\n",
       "      <th>Best Threshold</th>\n",
       "      <th>Min Error</th>\n",
       "      <th>Confidence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0[304] ðŸ€†ðŸ€†ðŸ€†ðŸ€†ðŸ€†ðŸ€†ðŸ€†ðŸ€†ðŸ€«ðŸ€«ðŸ€«ðŸ€«ðŸ€«ðŸ€«ðŸ€«ðŸ€« 0[1464]</td>\n",
       "      <td>1</td>\n",
       "      <td>0.453672</td>\n",
       "      <td>0.185844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0[1752] ðŸ€†ðŸ€†ðŸ€†ðŸ€†ðŸ€«ðŸ€«ðŸ€«ðŸ€« 0[24]</td>\n",
       "      <td>1</td>\n",
       "      <td>0.459875</td>\n",
       "      <td>0.160845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0[328] ðŸ€«ðŸ€«ðŸ€«ðŸ€«ðŸ€†ðŸ€†ðŸ€†ðŸ€† 0[1448]</td>\n",
       "      <td>1</td>\n",
       "      <td>0.460774</td>\n",
       "      <td>0.157226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0[304] ðŸ€«ðŸ€«ðŸ€«ðŸ€«ðŸ€«ðŸ€«ðŸ€«ðŸ€«ðŸ€«ðŸ€«ðŸ€«ðŸ€«ðŸ€«ðŸ€«ðŸ€«ðŸ€« 0[1464]</td>\n",
       "      <td>2</td>\n",
       "      <td>0.461820</td>\n",
       "      <td>0.153019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0[1664] ðŸ€«ðŸ€«ðŸ€«ðŸ€«ðŸ€«ðŸ€«ðŸ€«ðŸ€«ðŸ€«ðŸ€«ðŸ€«ðŸ€«ðŸ€«ðŸ€«ðŸ€«ðŸ€« 0[104]</td>\n",
       "      <td>1</td>\n",
       "      <td>0.459515</td>\n",
       "      <td>0.162296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>0[16] ðŸ€«ðŸ€«ðŸ€«ðŸ€«ðŸ€†ðŸ€†ðŸ€†ðŸ€† 0[1760]</td>\n",
       "      <td>1</td>\n",
       "      <td>0.288404</td>\n",
       "      <td>0.903146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>0[472] ðŸ€†ðŸ€†ðŸ€†ðŸ€†ðŸ€«ðŸ€«ðŸ€«ðŸ€« 0[1304]</td>\n",
       "      <td>1</td>\n",
       "      <td>0.288404</td>\n",
       "      <td>0.903146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>0[976] ðŸ€«ðŸ€«ðŸ€«ðŸ€«ðŸ€†ðŸ€†ðŸ€†ðŸ€† 0[800]</td>\n",
       "      <td>1</td>\n",
       "      <td>0.288404</td>\n",
       "      <td>0.903146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>0[152] ðŸ€«ðŸ€«ðŸ€«ðŸ€«ðŸ€†ðŸ€†ðŸ€†ðŸ€† 0[1624]</td>\n",
       "      <td>1</td>\n",
       "      <td>0.288404</td>\n",
       "      <td>0.903146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>0[1560] ðŸ€«ðŸ€«ðŸ€«ðŸ€«ðŸ€«ðŸ€«ðŸ€«ðŸ€« 0[216]</td>\n",
       "      <td>1</td>\n",
       "      <td>0.288404</td>\n",
       "      <td>0.903146</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>114 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Best Filter  Best Threshold  Min Error  Confidence\n",
       "0    0[304] ðŸ€†ðŸ€†ðŸ€†ðŸ€†ðŸ€†ðŸ€†ðŸ€†ðŸ€†ðŸ€«ðŸ€«ðŸ€«ðŸ€«ðŸ€«ðŸ€«ðŸ€«ðŸ€« 0[1464]               1   0.453672    0.185844\n",
       "1             0[1752] ðŸ€†ðŸ€†ðŸ€†ðŸ€†ðŸ€«ðŸ€«ðŸ€«ðŸ€« 0[24]               1   0.459875    0.160845\n",
       "2            0[328] ðŸ€«ðŸ€«ðŸ€«ðŸ€«ðŸ€†ðŸ€†ðŸ€†ðŸ€† 0[1448]               1   0.460774    0.157226\n",
       "3    0[304] ðŸ€«ðŸ€«ðŸ€«ðŸ€«ðŸ€«ðŸ€«ðŸ€«ðŸ€«ðŸ€«ðŸ€«ðŸ€«ðŸ€«ðŸ€«ðŸ€«ðŸ€«ðŸ€« 0[1464]               2   0.461820    0.153019\n",
       "4    0[1664] ðŸ€«ðŸ€«ðŸ€«ðŸ€«ðŸ€«ðŸ€«ðŸ€«ðŸ€«ðŸ€«ðŸ€«ðŸ€«ðŸ€«ðŸ€«ðŸ€«ðŸ€«ðŸ€« 0[104]               1   0.459515    0.162296\n",
       "..                               ...             ...        ...         ...\n",
       "109           0[16] ðŸ€«ðŸ€«ðŸ€«ðŸ€«ðŸ€†ðŸ€†ðŸ€†ðŸ€† 0[1760]               1   0.288404    0.903146\n",
       "110          0[472] ðŸ€†ðŸ€†ðŸ€†ðŸ€†ðŸ€«ðŸ€«ðŸ€«ðŸ€« 0[1304]               1   0.288404    0.903146\n",
       "111           0[976] ðŸ€«ðŸ€«ðŸ€«ðŸ€«ðŸ€†ðŸ€†ðŸ€†ðŸ€† 0[800]               1   0.288404    0.903146\n",
       "112          0[152] ðŸ€«ðŸ€«ðŸ€«ðŸ€«ðŸ€†ðŸ€†ðŸ€†ðŸ€† 0[1624]               1   0.288404    0.903146\n",
       "113          0[1560] ðŸ€«ðŸ€«ðŸ€«ðŸ€«ðŸ€«ðŸ€«ðŸ€«ðŸ€« 0[216]               1   0.288404    0.903146\n",
       "\n",
       "[114 rows x 4 columns]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_configs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "if M != 0:\n",
    "    best_configs_df = best_configs_df.head(M)\n",
    "\n",
    "if M == 0:\n",
    "    M = len(best_configs_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compression Rate: 111.5\n"
     ]
    }
   ],
   "source": [
    "compression_rate = len(string_df[\"concatenated\"].iloc[0]) / best_configs_df.shape[0]\n",
    "\n",
    "print(\"Compression Rate:\", compression_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filters Parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_parser(input_string: str) -> list:\n",
    "    # Split the string into its parts\n",
    "    parts = input_string.split()\n",
    "\n",
    "    # Initialize the final array\n",
    "    result = []\n",
    "\n",
    "    # Process each part\n",
    "    for part in parts:\n",
    "        if part.startswith(\"0[\"):\n",
    "            # Extract the number inside the brackets\n",
    "            count = int(part[2:-1])\n",
    "            # Append the corresponding number of zeros to the result\n",
    "            result.extend([0] * count)\n",
    "        else:\n",
    "            # Translate the tiles to their respective values\n",
    "            for char in part:\n",
    "                if char == \"ðŸ€†\":\n",
    "                    result.append(-1)\n",
    "                elif char == \"ðŸ€«\":\n",
    "                    result.append(1)\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import time\n",
    "\n",
    "# time.sleep(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply Filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_filter(item, filter):\n",
    "    # item = np.array(list(item)).astype(int)\n",
    "    item = item.astype(int)\n",
    "    filter = filter_parser(filter)\n",
    "    return np.sum(np.multiply(item, filter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_filter_threshold(item, filter, threshold) -> int:\n",
    "    if apply_filter(item, filter) > threshold:\n",
    "        return 1\n",
    "    else:\n",
    "        return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_filter_threshold_pair(item_1, item_2, filter, threshold) -> int:\n",
    "    if apply_filter_threshold(item_1, filter, threshold) == apply_filter_threshold(\n",
    "        item_2, filter, threshold\n",
    "    ):\n",
    "        return 1\n",
    "    else:\n",
    "        return -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Fingerprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hamming_distance(array1, array2, confidence):\n",
    "    # Check if arrays have the same length\n",
    "    if len(array1) != len(array2):\n",
    "        raise ValueError(\"Arrays must have the same length\")\n",
    "\n",
    "    # Initialize distance counter\n",
    "    distance = 0\n",
    "\n",
    "    # Iterate through arrays and count differences\n",
    "    for i in range(len(array1)):\n",
    "        if array1[i] != array2[i]:\n",
    "            distance += confidence[i]\n",
    "\n",
    "    distance = (distance / sum(confidence)) * len(confidence)\n",
    "\n",
    "    return distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_fingerprint(item, best_filters, best_thresholds, confidence):\n",
    "    fingerprint = []\n",
    "\n",
    "    for best_filter, best_threshold in zip(best_filters, best_thresholds):\n",
    "        filtered = np.sum(np.multiply(item.astype(int), filter_parser(best_filter)))\n",
    "\n",
    "        if filtered > best_threshold:\n",
    "            filtered = 1\n",
    "        else:\n",
    "            filtered = -1\n",
    "\n",
    "        fingerprint.append(filtered)\n",
    "\n",
    "    return fingerprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "fingerprints = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e2b59ed1fe345a095397c17428adbdb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/956 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i, row in tqdm(string_df.iterrows(), total=string_df.shape[0]):\n",
    "    # Extracting best filters and thresholds from the main DataFrame\n",
    "    best_filters = best_configs_df[\"Best Filter\"].tolist()\n",
    "    best_thresholds = best_configs_df[\"Best Threshold\"].tolist()\n",
    "    confidence = best_configs_df[\"Confidence\"].tolist()\n",
    "\n",
    "    # Calculate the fingerprint using the relevant best filters and thresholds\n",
    "    fingerprint = calculate_fingerprint(\n",
    "        row[\"concatenated\"], best_filters, best_thresholds, confidence\n",
    "    )\n",
    "\n",
    "    # Store the result in the 'fprint' column\n",
    "    # string_df.at[i, \"fprint\"] = fingerprint\n",
    "    fingerprints.append(fingerprint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "string_df[\"fprint\"] = fingerprints"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering w/ Cosine Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "string_df = string_df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>concatenated</th>\n",
       "      <th>fprint</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GooglePixel3A_L</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[1, 1, 1, 1, -1, 1, 1, -1, 1, 1, -1, -1, 1, -1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GooglePixel3A_L</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, -1, 1, 1, -1, -1, 1, -1,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GooglePixel3A_L</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[1, 1, -1, 1, -1, 1, 1, -1, 1, 1, -1, -1, 1, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GooglePixel3A_L</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, -1, 1, 1, -1, -1, 1, -1,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GooglePixel3A_L</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[1, 1, 1, 1, -1, 1, 1, -1, 1, 1, -1, -1, 1, -1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>951</th>\n",
       "      <td>iPhoneXSMax_M</td>\n",
       "      <td>[0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, ...</td>\n",
       "      <td>[-1, 1, -1, -1, -1, -1, 1, -1, 1, 1, 1, -1, -1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>952</th>\n",
       "      <td>iPhoneXSMax_M</td>\n",
       "      <td>[0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, ...</td>\n",
       "      <td>[-1, -1, -1, -1, -1, -1, -1, 1, -1, -1, 1, -1,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>953</th>\n",
       "      <td>iPhoneXSMax_M</td>\n",
       "      <td>[0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, ...</td>\n",
       "      <td>[-1, -1, -1, -1, -1, -1, 1, -1, -1, 1, 1, -1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>954</th>\n",
       "      <td>iPhoneXSMax_M</td>\n",
       "      <td>[0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, ...</td>\n",
       "      <td>[-1, 1, -1, -1, 1, -1, 1, 1, 1, 1, 1, -1, -1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>955</th>\n",
       "      <td>iPhoneXSMax_M</td>\n",
       "      <td>[0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, ...</td>\n",
       "      <td>[-1, 1, -1, -1, 1, -1, 1, 1, 1, 1, 1, -1, -1, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>956 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               label                                       concatenated  \\\n",
       "0    GooglePixel3A_L  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "1    GooglePixel3A_L  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "2    GooglePixel3A_L  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "3    GooglePixel3A_L  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "4    GooglePixel3A_L  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "..               ...                                                ...   \n",
       "951    iPhoneXSMax_M  [0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, ...   \n",
       "952    iPhoneXSMax_M  [0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, ...   \n",
       "953    iPhoneXSMax_M  [0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, ...   \n",
       "954    iPhoneXSMax_M  [0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, ...   \n",
       "955    iPhoneXSMax_M  [0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, ...   \n",
       "\n",
       "                                                fprint  \n",
       "0    [1, 1, 1, 1, -1, 1, 1, -1, 1, 1, -1, -1, 1, -1...  \n",
       "1    [1, 1, 1, 1, 1, 1, 1, -1, 1, 1, -1, -1, 1, -1,...  \n",
       "2    [1, 1, -1, 1, -1, 1, 1, -1, 1, 1, -1, -1, 1, -...  \n",
       "3    [1, 1, 1, 1, 1, 1, 1, -1, 1, 1, -1, -1, 1, -1,...  \n",
       "4    [1, 1, 1, 1, -1, 1, 1, -1, 1, 1, -1, -1, 1, -1...  \n",
       "..                                                 ...  \n",
       "951  [-1, 1, -1, -1, -1, -1, 1, -1, 1, 1, 1, -1, -1...  \n",
       "952  [-1, -1, -1, -1, -1, -1, -1, 1, -1, -1, 1, -1,...  \n",
       "953  [-1, -1, -1, -1, -1, -1, 1, -1, -1, 1, 1, -1, ...  \n",
       "954  [-1, 1, -1, -1, 1, -1, 1, 1, 1, 1, 1, -1, -1, ...  \n",
       "955  [-1, 1, -1, -1, 1, -1, 1, 1, 1, 1, 1, -1, -1, ...  \n",
       "\n",
       "[956 rows x 3 columns]"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(string_df[\"fprint\"].iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(arr1, arr2):\n",
    "    \"\"\"\n",
    "    Compute cosine similarity between two arrays.\n",
    "\n",
    "    Parameters:\n",
    "    arr1 : numpy array\n",
    "        First array.\n",
    "    arr2 : numpy array\n",
    "        Second array.\n",
    "\n",
    "    Returns:\n",
    "    float\n",
    "        Cosine similarity between arr1 and arr2.\n",
    "    \"\"\"\n",
    "    dot_product = np.dot(arr1, arr2)\n",
    "    norm_arr1 = np.linalg.norm(arr1)\n",
    "    norm_arr2 = np.linalg.norm(arr2)\n",
    "    similarity = dot_product / (norm_arr1 * norm_arr2)\n",
    "\n",
    "    return similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.metrics import homogeneity_score, completeness_score, v_measure_score\n",
    "\n",
    "# Example dataframe setup (replace this with your actual dataframe)\n",
    "# string_df = pd.DataFrame({'label': labels, 'fprint': fingerprints, 'concatenated_fprint': concatenated_fingerprints})\n",
    "\n",
    "# Extract arrays from dataframe\n",
    "data_points = string_df[\"fprint\"].values\n",
    "labels_true = string_df[\"label\"].values\n",
    "\n",
    "\n",
    "# Compute cosine similarity between each pair of data points\n",
    "def compute_cosine_similarity_matrix(data_points):\n",
    "    num_points = len(data_points)\n",
    "    similarity_matrix = np.zeros((num_points, num_points))\n",
    "\n",
    "    for i in range(num_points):\n",
    "        for j in range(i, num_points):\n",
    "            # Reshape arrays to ensure they are 2D\n",
    "            array1 = np.array(data_points[i]).reshape(1, -1)\n",
    "            array2 = np.array(data_points[j]).reshape(1, -1)\n",
    "            similarity = cosine_similarity(array1, array2)[0, 0]\n",
    "            similarity_matrix[i, j] = similarity\n",
    "            similarity_matrix[j, i] = similarity\n",
    "\n",
    "    return similarity_matrix\n",
    "\n",
    "\n",
    "similarity_matrix = compute_cosine_similarity_matrix(data_points)\n",
    "\n",
    "# Example clustering (replace this with your actual clustering algorithm)\n",
    "# Here, clustering assignment is based on a cosine similarity threshold\n",
    "clusters = []\n",
    "cluster_indices = np.zeros(len(data_points), dtype=int)\n",
    "\n",
    "threshold = 0.65\n",
    "\n",
    "current_cluster_index = 0\n",
    "for i in range(len(data_points)):\n",
    "    if cluster_indices[i] == 0:\n",
    "        cluster_indices[i] = current_cluster_index\n",
    "        clusters.append([i])\n",
    "\n",
    "        for j in range(i + 1, len(data_points)):\n",
    "            if similarity_matrix[i, j] >= threshold:\n",
    "                if cluster_indices[j] == 0:\n",
    "                    cluster_indices[j] = current_cluster_index\n",
    "                    clusters[current_cluster_index].append(j)\n",
    "\n",
    "        current_cluster_index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Homogeneity: 0.6641\n",
      "Completeness: 0.7225\n",
      "V-measure: 0.6921\n"
     ]
    }
   ],
   "source": [
    "# Calculate evaluation metrics\n",
    "homogeneity = homogeneity_score(labels_true, cluster_indices)\n",
    "completeness = completeness_score(labels_true, cluster_indices)\n",
    "v_measure = v_measure_score(labels_true, cluster_indices)\n",
    "\n",
    "print(f\"Homogeneity: {homogeneity:.4f}\")\n",
    "print(f\"Completeness: {completeness:.4f}\")\n",
    "print(f\"V-measure: {v_measure:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(string_df[\"label\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(cluster_indices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
